{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import epps_singleton_2samp as epps\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from math import floor\n",
    "from mlxtend.evaluate import permutation_test\n",
    "\n",
    "MIN_SAMPLE_SIZE = 20\n",
    "MIN_SAMPLE_SIZE_2 = 45\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "sns.set(\n",
    "    context=\"paper\",\n",
    "    style=\"darkgrid\",\n",
    "    rc={\"figure.dpi\": 150}\n",
    ")\n",
    "df = pd.read_pickle('complete_lifetimes_v4.pd')\n",
    "df.c_lifetime = df.c_lifetime.astype(float)\n",
    "df_code_age = pd.read_json('codelifetimes.json', orient='index') \n",
    "\n",
    "def plot_hist_trend_complete(project, estimator=np.mean, stats = False, min=1900, max=2021, data=df, field='lifetime', debug=False, fit_reg=False, lw=0, lp=True, xlim=True, ylim=(0, 2600), label='Lifetime', color=None, f=True, marker='x', ci='ci', latex=False):\n",
    "    if f:\n",
    "        f = plt.figure()\n",
    "        f.set_figwidth(6)\n",
    "        f.set_figheight(3)\n",
    "    if project is None:\n",
    "        df_proj = data\n",
    "    else:\n",
    "        df_proj = data.loc[data.project == project] \n",
    "    df_proj = df_proj.loc[df_proj.fix_year >= min].loc[df_proj.fix_year <= max]\n",
    "    \n",
    "    df_counts = df_proj[['fix_year', field]].groupby(by='fix_year').count()\n",
    "    drop_years = list(df_counts.loc[df_counts[field] < MIN_SAMPLE_SIZE_2].index)\n",
    "    if debug:\n",
    "        print(df_counts)\n",
    "    df_proj = df_proj.loc[~df_proj.fix_year.isin(drop_years)]\n",
    "    \n",
    "    \n",
    "    ax = sns.regplot(data=df_proj, x='fix_year', y=field, x_estimator=estimator, x_ci=ci, marker=marker, truncate=False, fit_reg=fit_reg, label=label, color=color)\n",
    "    if lp:\n",
    "        sns.regplot(data=df_proj, x='fix_year', y='lp_lifetime', x_estimator=estimator, x_ci=None, marker='^', color='darkseagreen', truncate=False, fit_reg=False, label='Li&Paxson estimate')\n",
    "    ax.set_ylabel('lifetime in days')\n",
    "    ax.set_xlabel('year of fixing commit')\n",
    "    ax.set_ylim(ylim)\n",
    "    if  xlim:\n",
    "        ax.set_xlim((2007.5, 2020.5))\n",
    "    if df_proj.fix_year.min() > 2008 & lw > 0:\n",
    "        ax.axvline(0, color='grey', lw=8, alpha=0.6, label='Insufficient data')\n",
    "        ax.axvline(2007.5, color='grey', lw=lw, alpha=0.6)\n",
    "    \n",
    "    plt.legend()\n",
    "    if stats:\n",
    "        X = sorted(list(df_proj.fix_year.unique()))\n",
    "        X_ = sm.add_constant(X)\n",
    "        y = [estimator(df_proj.loc[df_proj.fix_year == x][field]) for x in X]\n",
    "        model = sm.OLS(y,X_).fit()\n",
    "        print(model.summary())\n",
    "        if latex:\n",
    "            print(model.summary().tables[1].as_latex_tabular())\n",
    "    return ax\n",
    "\n",
    "def plot_hist_trend_aggregated(project, estimator=np.mean, stats = False, min=1900, max=2021, data=df, field='lifetime', color='b', debug=False, latex=False):\n",
    "    if project is None:\n",
    "        df_proj = data\n",
    "    else:\n",
    "        df_proj = data.loc[data.project == project] \n",
    "        \n",
    "    #df_proj = df_proj.loc[df_proj.fix_year >= min].loc[df_proj.fix_year <= max]\n",
    "    if debug:\n",
    "        df_counts = df_proj[['fix_year', field]].groupby(by='fix_year').count()\n",
    "        print(df_counts)\n",
    "        \n",
    "    df_proj = df_proj.loc[df_proj.fix_year >= min].loc[df_proj.fix_year <= max]\n",
    "    bins = calculate_grouping_bins(data=df_proj, field=field, min_year=min, max_year=max)\n",
    "    if bins is None:\n",
    "        return None\n",
    "    df_proj['group_year'] = df_proj.fix_year.apply(lambda x: bins.loc[(bins.year_from < x) & (bins.year_to >= x)]['year_from'].min())\n",
    "    \n",
    "    ax = sns.pointplot(data=df_proj, x='group_year', y=field, estimator=estimator, color=color)\n",
    "    ax.set_xticklabels(bins['label'])\n",
    "    if stats:\n",
    "        X = sorted(list(df_proj.group_year.unique()))\n",
    "        X_ = sm.add_constant(X)\n",
    "        y = [estimator(df_proj.loc[df_proj.group_year == x][field]) for x in X]\n",
    "        model = sm.OLS(y,X_).fit()\n",
    "        print(model.summary())\n",
    "        if latex:\n",
    "            print(model.summary().tables[1].as_latex_tabular())\n",
    "    return ax\n",
    "\n",
    "def plot_code_age(data=df, project=None, plot_vul_lifetime=True, estimator=np.mean, aggregate=False, debug=False, min_year=1900, max_year = 2099, splits=None, latex=False):\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(3)\n",
    "    if project is None:\n",
    "        df_proj = df_code_age\n",
    "    else:\n",
    "        df_proj = df_code_age.loc[project].to_frame('age').dropna()\n",
    "    if plot_vul_lifetime:\n",
    "        df_vul = data.loc[data.project == project]\n",
    "        if debug:\n",
    "            df_counts = df_vul[['fix_year', 'lifetime']].groupby(by='fix_year').count()\n",
    "            print(df_counts)\n",
    "        if aggregate:\n",
    "            \n",
    "            \n",
    "            bins = calculate_grouping_bins(df_vul, min_year=min_year, max_year = max_year)\n",
    "            df_vul['group_year'] = df_vul.fix_year.apply(lambda x: bins.loc[(bins.year_from < x) & (bins.year_to >= x)]['year_from'].min())\n",
    "            for it, item  in enumerate(bins.iterrows()):\n",
    "                index, row = item\n",
    "                data_vul = df_vul.loc[df_vul.group_year == row.year_from]\n",
    "                val = np.mean(data_vul.lifetime)\n",
    "                if it == 0:\n",
    "                    plt.plot([row.year_from, row.year_to], [val, val], color='b', linewidth=3, label='Vul lifetime')\n",
    "                else: \n",
    "                    plt.plot([row.year_from, row.year_to], [val, val], color='b', linewidth=3)\n",
    "\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plot_hist_trend_complete(data=data, project=project, stats=False, fit_reg=True, lp=False, estimator=estimator, xlim=False, ylim=(0,4200), ci=None, latex=latex)\n",
    "    \n",
    "     \n",
    "    df_proj['year'] = df_proj.index\n",
    "    if splits:\n",
    "        for split in splits:\n",
    "            df_proj_split = df_proj.loc[df_proj.year >= split[0]].loc[df_proj.year <= split[1]]\n",
    "            ax = sns.regplot(data=df_proj_split, x='year', y='age', x_estimator=estimator, x_ci=None, marker='s', truncate=True, label='Regular code age', color='orchid')\n",
    "    else:\n",
    "        ax = sns.regplot(data=df_proj, x='year', y='age', x_estimator=estimator, x_ci=None, marker='s', truncate=False, label='Regular code age', color='orchid')\n",
    "    ax.set_ylabel('lifetime in days')\n",
    "    ax.set_xlabel('year of fixing commit')\n",
    "    ax.set_ylim((0,4200))\n",
    "    plt.legend()\n",
    "    return ax\n",
    "    \n",
    "def plot_lifetime_distribution(project, fit=False, test=False, data=df, field='lifetime', bins=100, color='b', f=True):\n",
    "    if f:\n",
    "        f = plt.figure()\n",
    "        f.set_figwidth(6)\n",
    "        f.set_figheight(3)\n",
    "    if project is None:\n",
    "        df_proj = data\n",
    "    else:\n",
    "        df_proj = data.loc[data.project == project]\n",
    "    a, b = stats.expon.fit(df_proj[field])\n",
    "    if test:\n",
    "        print(f'Distribution parameters: {a}, {b}')\n",
    "    x = np.arange(0, df_proj.lifetime.max(), 10)\n",
    "    y =  stats.expon.pdf(x, a, b)\n",
    "    if fit:\n",
    "        sns.lineplot(x=x, y=y, label='Exponential fit', color=color)\n",
    "    ax = sns.histplot(data=df_proj, x=field, bins=bins, stat='density', cumulative=False, color=color)\n",
    "    ax.set_xlim((0, df_proj.lifetime.max()))\n",
    "    \n",
    "    mean = np.mean(df_proj[field])\n",
    "    median = np.median(df_proj[field])\n",
    "    for p in ax.patches:\n",
    "        if p.xy[0]< mean and mean <= p.xy[0]+p.get_width():\n",
    "            p.set_color('tab:red')\n",
    "            plt.axvline(-100, color='tab:red', lw=1.5, label='Mean')\n",
    "            height = stats.expon.pdf([p.xy[0]+0.5*p.get_width()], a, b)\n",
    "            p.set_height(height[0])\n",
    "        if p.xy[0]< median and median <= p.xy[0]+p.get_width():\n",
    "            p.set_color('tab:orange')\n",
    "            plt.axvline(-100, color='tab:orange', lw=1.5, label='Median')\n",
    "            height = stats.expon.pdf([p.xy[0]+0.5*p.get_width()], a, b)\n",
    "            p.set_height(height[0])\n",
    "    plt.legend()\n",
    "    if test:\n",
    "        print(stats.kstest(df_proj[field], stats.expon.cdf, [a, b]))\n",
    "        y = stats.expon.rvs(a, b, size=4700).astype(int)\n",
    "        print(epps(data[field], y))\n",
    "       \n",
    "    return ax\n",
    "\n",
    "def generate_lifetime_table(field, include_summary=False, fieldname=None, data=df, lifetime_field='lifetime'):\n",
    "    if fieldname is None:\n",
    "        fieldname = field\n",
    "    field_avgs = pd.DataFrame(columns=[fieldname, 'Average', 'Median', 'Std. Deviation', 'Covariance'])\n",
    "    for field_val in data[field].unique():\n",
    "        if pd.isnull(field_val):\n",
    "            continue\n",
    "        df_field = data.loc[data[field] == field_val]\n",
    "        field_avgs = field_avgs.append({fieldname: field_val, 'Average': np.mean(df_field[lifetime_field]), 'Median': np.median(df_field[lifetime_field])\n",
    "                            , 'Std. Deviation': np.std(df_field[lifetime_field]), 'Covariance': np.cov(df_field[lifetime_field])}, ignore_index=True)\n",
    "    if include_summary:\n",
    "        field_avgs = field_avgs.append({fieldname: 'Macro Avg.', 'Average': np.mean(field_avgs.Average), 'Median': np.mean(field_avgs.Median)\n",
    "                            , 'Std. Deviation': np.mean(field_avgs['Std. Deviation']), 'Covariance': np.mean(field_avgs['Covariance'])}, ignore_index=True)\n",
    "        field_avgs = field_avgs.append({fieldname: 'Overall', 'Average': np.mean(data[lifetime_field]), 'Median': np.median(data[lifetime_field])\n",
    "                            , 'Std. Deviation': np.std(data[lifetime_field]), 'Covariance': np.cov(data[lifetime_field])}, ignore_index=True)\n",
    "    field_avgs.set_index(fieldname, inplace=True)\n",
    "    return field_avgs\n",
    "\n",
    "def top_cat_samples(data=df, field='lifetime'):\n",
    "    s_1 = data.loc[data.cat == 1][field]\n",
    "    s_2 = data.loc[data.cat == 2][field]\n",
    "    s_3 = data.loc[data.cat == 3][field]\n",
    "    s_4 = data.loc[data.cat == 4][field]\n",
    "    s_5 = data.loc[data.cat == 5][field]\n",
    "    s_6 = data.loc[data.cat == 6][field]\n",
    "    return s_1, s_2, s_3, s_4, s_5, s_6\n",
    "\n",
    "def calculate_grouping_bins(data=df, field='lifetime', min_year=0, max_year=2099):\n",
    "    data = data.loc[data.fix_year >= min_year].loc[data.fix_year <= max_year]\n",
    "    df_counts = data[['fix_year', field]].groupby(by='fix_year').count()\n",
    "    bins = df_counts.shape[0]\n",
    "    while bins > 1:\n",
    "        df_group = pd.DataFrame(columns=['year_from', 'year_to', 'count', 'label'])\n",
    "        _, x = pd.cut(df_counts.index, bins=bins, retbins = True)\n",
    "        min = x[0]\n",
    "        for max in x[1:]:\n",
    "            df_group = df_group.append({'year_from': min, 'year_to' :max\n",
    "                                        , 'count': df_counts.loc[(df_counts.index > min) & (df_counts.index <= max)][field].sum(),\n",
    "                                        'label': f'{floor(min+1)}-{floor(max)}'}\n",
    "                                       , ignore_index =True)\n",
    "            min = max     \n",
    "        if(df_group['count'].min() >= MIN_SAMPLE_SIZE):\n",
    "            break\n",
    "        bins -= 1\n",
    "        \n",
    "    if(df_group['count'].min() >= MIN_SAMPLE_SIZE):\n",
    "        return df_group\n",
    "    else:\n",
    "        warnings.warn('Not enough data to group!')\n",
    "        return None\n",
    "def pairwise_permutation(values, num_rounds=100000, seed=42, detail=False, sig_level=0.05, bonf_corr = True):\n",
    "    p_values = []\n",
    "    for cat_1, value_1 in enumerate(values, start=1):\n",
    "        try:\n",
    "            name_1 = list(df.loc[df.cat == cat_1].cat_name)[0]\n",
    "        except:\n",
    "            name_1 = str(cat_1)\n",
    "        for cat_2, value_2 in enumerate(values[cat_1:], start=cat_1 +1):\n",
    "            try:\n",
    "                name_2 =  list(df.loc[df.cat == cat_2].cat_name)[0]\n",
    "            except:\n",
    "                name_2 = str(cat_2)\n",
    "            p_value = permutation_test(value_1, value_2, method='approximate',\n",
    "                           num_rounds=num_rounds,\n",
    "                           seed=seed)\n",
    "            if detail:\n",
    "                print(f'{f\"{p_value:0.4f}\":<10} {name_1:<45} {name_2:<30}')\n",
    "            p_values.append(p_value)\n",
    "    p_values = np.array(p_values)\n",
    "    if bonf_corr:\n",
    "        sig = np.count_nonzero(p_values < sig_level/len(p_values))\n",
    "    else:\n",
    "        sig = np.count_nonzero(p_values < sig_level)\n",
    "    print(f'{sig}/{p_values.shape[0]}={(sig/p_values.shape[0])*100:<0.2f}% of pairwise comparisons signficiant (Î±={sig_level*100:<0.1f}%)')\n",
    "\n",
    "def kl_divergence(data=df, field='lifetime', bins=100):\n",
    "    n, bins = np.histogram(data[field], bins = bins, density=True)\n",
    "\n",
    "    x = np.convolve(bins, np.ones(2), 'valid') / 2\n",
    "    a, b = stats.expon.fit(data[field])\n",
    "    y_exp = stats.expon.pdf(x, a, b)\n",
    "\n",
    "    #kl_divergence(y_true, n)\n",
    "    return -1 * np.sum(np.where((y_exp != 0), y_exp * np.log(n / y_exp), 0))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.project == 'chrome'].sort_values(by='c_lifetime', ascending=False).head(n=50)[['project', 'cve', 'h_lifetime', 'c_lifetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[pd.isna(df.c_lifetime) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per Project Lifetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_lifetime_table('project', include_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historic Trends\n",
    "\n",
    "Minima and Maxima for the analyis result from previous examination of the data. These are the boundaries that ensure the discussed criterion of at least 20 data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_complete(None, stats=True, min=2008, fit_reg=True, ci=None, ylim=(0,2500))\n",
    "plt.savefig('../out/year_trends/year_trend_All.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_complete('chrome', stats=True, latex=True, debug=False, fit_reg=True, lw=102)\n",
    "plt.savefig('../out/year_trends/year_trend_chrome.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_complete('firefox', stats=True, fit_reg=True, latex=False)\n",
    "plt.savefig('../out/year_trends/year_trend_firefox.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_complete('kernel', stats=True, lw=157, fit_reg=True, latex=False)\n",
    "plt.savefig('../out/year_trends/year_trend_kernel.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wireshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_complete('wireshark', stats=True, latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Httpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('httpd', stats=True, latex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Openssl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('openssl', stats=False, debug=True, latex=False, min=2006, max=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('php', stats=False, latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('postgres', stats=False, latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('qemu', stats=True, latex=False, min=2014, max=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TcpDump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('tcpdump', stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wireshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_trend_aggregated('wireshark', stats=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifetime Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitter import Fitter\n",
    "f = Fitter(df.lifetime)\n",
    "f.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_lifetime_distribution(project=None, fit=True, test=True, bins=200)\n",
    "print(f'Bin-width: {ax.patches[0].get_width()}')\n",
    "plt.savefig('../out/distributions/distribution_All_pdf.pdf', bbox_inches='tight', lw=100)\n",
    "kl_divergence(data=df.loc[df.lifetime < 6100])\n",
    "mean = np.mean(df.lifetime)\n",
    "print(f'{df.loc[df.lifetime < mean].shape[0] / df.shape[0] *100 :0.2f}% of vulnerabilities are fixed before the average of {mean:0.2f} days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, scale = stats.expon.fit(df.lifetime)\n",
    "h= sm.qqplot(df.lifetime, stats.expon, loc=loc, scale=scale, line='45', markerfacecolor='b')\n",
    "h.axes[0].set_xlim([0, 6500])\n",
    "h.axes[0].set_ylim([0, 6500])\n",
    "h.axes[0].set_xlabel('Exponential theoretical quantiles')\n",
    "h.axes[0].set_ylabel('Sample quantiles')\n",
    "plt.savefig('../out/distributions/qq_plot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff= 5000\n",
    "data = df.loc[df.lifetime > 0]\n",
    "print(f'Data: Percentage of vuls over {cutoff} {data.loc[data.lifetime > cutoff].shape[0] / data.shape[0]: 0.4f}')\n",
    "a, b = stats.expon.fit(data.lifetime)\n",
    "print(f'Theoretical: Percentage of vuls over {cutoff}  {1-stats.expon.cdf(cutoff, a, b):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powerlaw\n",
    "results = powerlaw.Fit(df.lifetime.to_list(), xmin=0.1)\n",
    "print(f\"Exponential vs power_law: {results.distribution_compare('exponential', 'power_law')}\")\n",
    "print(f\"Exponential vs lognormal: {results.distribution_compare('exponential', 'lognormal')}\")\n",
    "print(f\"Exponential vs truncated_power_law: {results.distribution_compare('exponential', 'truncated_power_law')}\")\n",
    "print(f\"Exponential vs lognormal_positive: {results.distribution_compare('exponential', 'lognormal_positive')}\")    \n",
    "print()\n",
    "print(results.distribution_compare('stretched_exponential', 'exponential'))\n",
    "print()\n",
    "print(results.distribution_compare('stretched_exponential', 'lognormal'))\n",
    "print(results.distribution_compare('stretched_exponential', 'lognormal_positive'))\n",
    "print(results.distribution_compare('stretched_exponential', 'power_law'))\n",
    "print(results.distribution_compare('stretched_exponential', 'truncated_power_law'))\n",
    "\n",
    "print(f'Stretching factor: {results.stretched_exponential.beta}')\n",
    "\n",
    "\n",
    "\n",
    "#ax = sns.histplot(data=df, x='lifetime', bins=200, stat='density', cumulative=False, color='b')\n",
    "ax = results.plot_pdf(label='Data density')\n",
    "ax = results.exponential.plot_pdf(ax=ax, label='Exp')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "ax = results.plot_ccdf(label='Data density')\n",
    "ax = results.stretched_exponential.plot_ccdf(label='Stretched', ax=ax)\n",
    "ax = results.exponential.plot_ccdf(ax=ax, label='Exp')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical vs Theoretical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "data = df.loc[df.lifetime > 0]\n",
    "a, b = stats.expon.fit(data.lifetime)\n",
    "q = 0.1\n",
    "for i in range(2, 11):\n",
    "    cutoff = np.quantile(data.lifetime, q)\n",
    "    print(f'{f\"{q:0.1f}\":<4} {f\"{cutoff:0.0f}\":<10} {f\"{stats.expon.cdf(cutoff, a, b):0.4f}\":<10} {f\"{data.loc[data.lifetime <= cutoff].shape[0] /data.shape[0]:0.4f}\":<10}')\n",
    "    q = i * 0.1\n",
    "\n",
    "print()\n",
    "q = 0.95\n",
    "cutoff = np.quantile(data.lifetime, q)\n",
    "print(f'{f\"{q:0.2f}\":<4} {f\"{cutoff:0.0f}\":<10} {f\"{stats.expon.cdf(cutoff, a, b):0.4f}\":<10} {f\"{data.loc[data.lifetime <= cutoff].shape[0] /data.shape[0]:0.4f}\":<10}')\n",
    "\n",
    "q = 0.99\n",
    "cutoff = np.quantile(data.lifetime, q)\n",
    "print(f'{f\"{q:0.2f}\":<4} {f\"{cutoff:0.0f}\":<10} {f\"{stats.expon.cdf(cutoff, a, b):0.4f}\":<10} {f\"{data.loc[data.lifetime <= cutoff].shape[0] /data.shape[0]:0.4f}\":<10}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime Distributions per project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lifetime_distribution(project='firefox', fit=True, test=False)\n",
    "plt.savefig('../out/distributions/distribution_firefox_pdf.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lifetime_distribution(project='chrome', fit=True, test=False)\n",
    "plt.savefig('../out/distributions/distribution_chrome_pdf.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lifetime_distribution(project='kernel', fit=True, test=False)\n",
    "plt.savefig('../out/distributions/distribution_linux_pdf.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wireshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lifetime_distribution(project='wireshark', fit=True, test=True, bins=50)\n",
    "plt.savefig('../out/distributions/distribution_wireshark_pdf.pdf', bbox_inches='tight', lw=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historic Development of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [2013, 2015, 2017, 2020]\n",
    "prev_year = 0\n",
    "for year in cutoffs:\n",
    "    data = df.loc[df.fix_year > prev_year].loc[df.fix_year <=year]\n",
    "    a, b = stats.expon.fit(data.lifetime)\n",
    "    x = np.arange(0, df.lifetime.max(), 10)\n",
    "    y =  stats.expon.pdf(x, a, b)\n",
    "    sns.lineplot(x=x, y=y, label=f'Exponential fit <= {year}')\n",
    "plt.savefig('../out/distributions/distribution_All_split_4_pdf.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vulnerabiltiy types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, s6 = top_cat_samples()\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "generate_lifetime_table('cat_name', include_summary=False)\n",
    "#df_temp = generate_lifetime_table('cat_name', include_summary=False)[ 'Average']\n",
    "#df_temp.to_latex()\n",
    "#pairwise_permutation([s1, s2, s3, s4, s5, s6], num_rounds=10000, detail=True, bonf_corr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'chrome'])\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "generate_lifetime_table('cat_name', include_summary=False, data=df.loc[df.project == 'chrome'])\n",
    "#df_temp = generate_lifetime_table('cat_name', include_summary=False, data=df.loc[df.project == 'chrome'])[ 'Average']\n",
    "#df_temp.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'firefox'])\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "generate_lifetime_table('cat_name', include_summary=False, data=df.loc[df.project == 'firefox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'kernel'])\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "generate_lifetime_table('cat_name', include_summary=False, data=df.loc[df.project == 'kernel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison against Li&Paxson\n",
    "\n",
    "To confirm these results we show that we would arrive at the same conclusion using the lower bound approach of Li&Paxson. (Note: This lowerbound is not identical to the one proposed by Li&Paxson but instead the equivalent of considering the newest blamed VCC candidate from our heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(field='lp_lifetime')\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "generate_lifetime_table('cat_name', include_summary=False, lifetime_field='lp_lifetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again only looking at the statistics over all the projects we would confidently reject the Null-hypothesis that the categories follow the same distribution. Thus, arriving at the conclusion that there is a significant difference in lifetime between categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1mChrome:\\n\\033[0m')\n",
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'chrome'], field='lp_lifetime')\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "print('')\n",
    "print('\\033[1mFirefox:\\n\\033[0m')\n",
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'firefox'], field='lp_lifetime')\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))\n",
    "pairwise_permutation([s1, s2, s3, s4, s5, s6], num_rounds=1000, detail=True)\n",
    "print('')\n",
    "print('\\033[1mLinux kernel:\\n\\033[0m')\n",
    "s1, s2, s3, s4, s5, s6 = top_cat_samples(df.loc[df.project == 'kernel'], field='lp_lifetime')\n",
    "print(stats.kruskal(s1, s2, s3, s4, s5, s6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of lifetimetrends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_kernel = df.loc[df.project == 'kernel']\n",
    "\n",
    "df_mem = df.loc[df.cat == 1]\n",
    "print(len(df_mem)/len(df))\n",
    "plot_hist_trend_complete(project=None, data=df_mem, lp=None, ci=None, xlim=None, debug=False, color='r', label='Memory vulnerabilities', max=2020, fit_reg=True)\n",
    "df_others = df.loc[df.cat != 1]\n",
    "print(len(df_others)/len(df))\n",
    "plot_hist_trend_complete(project=None, data=df_others, lp=None, ci=None, xlim=None, debug=False, min=2010, color='g', f=False, label='Others', max=2020, fit_reg=True, marker='+')\n",
    "plt.savefig('../out/year_trends/year_trend_all_mem_vs_others.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLE_SIZE_2 = 20\n",
    "df_kernel = df.loc[df.project == 'kernel']\n",
    "df_mem = df_kernel.loc[df_kernel.cat == 1]\n",
    "print(len(df_mem)/len(df_kernel))\n",
    "plot_hist_trend_complete(debug=False, project=None, data=df_mem, lp=None, ci=None, xlim=None, color='r', label='Memory vulnerabilities', max=2020, fit_reg=True, ylim=[0, 2800])\n",
    "df_others = df_kernel.loc[df_kernel.cat != 1]\n",
    "print(len(df_others)/len(df_kernel))\n",
    "ax = plot_hist_trend_complete(project=None, data=df_others, lp=None, ci=None, xlim=None, debug=False, color='g', f=False, label='Others', max=2020, fit_reg=True, marker='+', ylim=None)\n",
    "ax.set_xticks(range(2011, 2021))\n",
    "MIN_SAMPLE_SIZE_2 = 45\n",
    "plt.savefig('../out/year_trends/year_trend_kernel_mem_vs_others.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLE_SIZE_2 = 20\n",
    "df_chrome = df.loc[df.project == 'chrome']\n",
    "df_mem = df_chrome.loc[df_chrome.cat == 1]\n",
    "print(len(df_mem)/len(df_chrome))\n",
    "plot_hist_trend_complete(debug=False, project=None, data=df_mem, lp=None, ci=None, xlim=None, color='r', label='Memory vulnerabilities', max=2020, fit_reg=True, ylim=None)\n",
    "df_others = df_chrome.loc[df_chrome.cat != 1]\n",
    "print(len(df_others)/len(df_chrome))\n",
    "plot_hist_trend_complete(project=None, data=df_others, lp=None, ci=None, xlim=None, debug=False, color='g', f=False, label='Others', min=2011, max=2020, fit_reg=True, marker='+', ylim=[0, 1200])\n",
    "MIN_SAMPLE_SIZE_2 = 45\n",
    "plt.savefig('../out/year_trends/year_trend_chrome_mem_vs_others.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLE_SIZE_2 = 20\n",
    "df_firefox = df.loc[df.project == 'firefox']\n",
    "df_mem = df_firefox.loc[df_firefox.cat == 1]\n",
    "print(len(df_mem)/len(df_firefox))\n",
    "plot_hist_trend_complete(debug=False, project=None, data=df_mem, lp=None, ci=None, xlim=None, color='r', label='Memory vulnerabilities',min=2012, max=2020, fit_reg=True, ylim=[0, 1950])\n",
    "df_others = df_firefox.loc[df_firefox.cat != 1]\n",
    "print(len(df_others)/len(df_firefox))\n",
    "plot_hist_trend_complete(project=None, data=df_others, lp=None, ci=None, xlim=None, debug=False, color='g', f=False, label='Others', min=2012, max=2020, fit_reg=True, marker='+', ylim=None)\n",
    "MIN_SAMPLE_SIZE_2 = 45\n",
    "plt.savefig('../out/year_trends/year_trend_firefox_mem_vs_others.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_others = df.loc[df.cat != 1]\n",
    "plot_hist_trend_complete(project=None, data=df_others)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for Chrome and the Linux Kernel support the hypothesis that differences in lifetime between categories are the result of an underlying in difference of categories per project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result comparision against ground truth\n",
    "In the final remarks from the reviewers we were asked to conduct the experiments regarding \n",
    " - average lifetime trend\n",
    " - distribution of lifetimes per year\n",
    "\n",
    "on the ground truth only and compare these results to the conclusions made on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average lifetime trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = df.loc[(df.c_lifetime.isna() == False)]\n",
    "#df_gt = df.loc[(df.c_lifetime.isna() == False) ]\n",
    "print(df_gt.shape[0])\n",
    "plot_hist_trend_complete(None, stats=False, min=2010, max=2019,  data=df_gt, field='c_lifetime', color='tab:orange')\n",
    "plot_hist_trend_complete(None, stats=False, min=2010, max=2019, data=df_gt, field='h_lifetime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLE_SIZE_2 = 35\n",
    "df_gt_kernel = df.loc[(df.c_lifetime.isna() == False) & (df.project == 'kernel')]\n",
    "plot_hist_trend_complete(None, debug=True, stats=True, data=df_gt_kernel, field='h_lifetime', xlim=None, fit_reg=True, lp=False, label='Heuristic Lifetime', ci=None)\n",
    "ax = plot_hist_trend_complete(None, stats=True, data=df_gt_kernel, field='c_lifetime', xlim=None, fit_reg=True, lp=False, label='Groundtruth lifetime', color='coral', f=False, marker='D', ci=None)\n",
    "ax.set_xticks(range(2011, 2021))\n",
    "plt.savefig('../out/year_trends/year_trend_linux_gt_comp.pdf', bbox_inches='tight')\n",
    "MIN_SAMPLE_SIZE_2 = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt_chrome = df.loc[(df.c_lifetime.isna() == False) & (df.project == 'chrome')]\n",
    "MIN_SAMPLE_SIZE_2 = 20\n",
    "plot_hist_trend_complete(None, stats=True, data=df_gt_chrome, field='c_lifetime', xlim=None, fit_reg=True, lp=False, label='Groundtruth lifetime', color='coral',  marker='D', ci=None)\n",
    "plot_hist_trend_complete(None, debug=True, stats=True, data=df_gt_chrome, field='h_lifetime', xlim=None, fit_reg=True, lp=False, label='Heuristic Lifetime', f=False, ci=None)\n",
    "\n",
    "plt.savefig('../out/year_trends/year_trend_chrome_gt_comp.pdf', bbox_inches='tight')\n",
    "MIN_SAMPLE_SIZE_2 = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Httpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt_httpd = df.loc[(df.c_lifetime.isna() == False) & (df.project == 'httpd')]\n",
    "plot_hist_trend_aggregated(None, stats=False, data=df_gt_httpd, field='h_lifetime')\n",
    "plot_hist_trend_aggregated(None, stats=False, data=df_gt_httpd, field='c_lifetime', color='tab:orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = df.loc[(df.c_lifetime.isna() == False)]\n",
    "ax = plot_lifetime_distribution(project=None, fit=True, test=True, field='h_lifetime', data=df_gt, bins=100, color='b')\n",
    "ax.set_xlabel('Heuristic lifetime (days)')\n",
    "#plt.figure()\n",
    "plt.savefig('../out/distributions/distribution_gtdata_heuristic.pdf', bbox_inches='tight')\n",
    "ax = plot_lifetime_distribution(project=None, fit=True, test=True, field='c_lifetime', data=df_gt, bins=100, color='coral')\n",
    "ax.set_xlabel('Ground truth lifetime (days)')\n",
    "plt.savefig('../out/distributions/distribution_gtdata_gt.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = df.loc[(df.c_lifetime.isna() == False)]\n",
    "loc, scale = stats.expon.fit(df_gt.h_lifetime)\n",
    "h= sm.qqplot(df_gt.h_lifetime, stats.expon, loc=loc, scale=scale, line='45', markerfacecolor='b')\n",
    "h.axes[0].set_xlim([0, 6500])\n",
    "h.axes[0].set_ylim([0, 6500])\n",
    "h.axes[0].set_xlabel('Exponential theoretical quantiles')\n",
    "h.axes[0].set_ylabel('Heuristic sample quantiles')\n",
    "plt.savefig('../out/distributions/qqplot_gtdata_heuristic.pdf', bbox_inches='tight')\n",
    "\n",
    "loc, scale = stats.expon.fit(df_gt.c_lifetime)\n",
    "gt = sm.qqplot(df_gt.c_lifetime, stats.expon, loc=loc, scale=scale, line='45', markerfacecolor='coral', color='coral')\n",
    "gt.axes[0].set_xlim([0, 6500])\n",
    "gt.axes[0].set_ylim([0, 6500])\n",
    "gt.axes[0].set_xlabel('Exponential theoretical quantiles')\n",
    "gt.axes[0].set_ylabel('Groundtruth sample quantiles')\n",
    "plt.savefig('../out/distributions/qqplot_gtdata_gt.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = [2013, 2015, 2017, 2020]\n",
    "prev_year = 0\n",
    "df_gt = df.loc[pd.isna(df.c_lifetime) == False]\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(3.5)\n",
    "for year in cutoffs:\n",
    "    data = df_gt.loc[df_gt.fix_year > prev_year].loc[df_gt.fix_year <=year]\n",
    "    a, b = stats.expon.fit(data.h_lifetime)\n",
    "    a = 0\n",
    "    x = np.arange(0, df.lifetime.max(), 10)\n",
    "    y =  stats.expon.pdf(x, a, b)\n",
    "    ax= sns.lineplot(x=x, y=y, label=f'Exponential fit <= {year}')\n",
    "\n",
    "ax.set_ylim([0, 0.0015])\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlabel('Heuristic lifetime (days)')\n",
    "plt.savefig('../out/distributions/distribution_all_split_4_gt_heuristic.pdf', bbox_inches='tight')\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(3.5)\n",
    "\n",
    "prev_year = 0\n",
    "for year in cutoffs:\n",
    "    data = df_gt.loc[df_gt.fix_year > prev_year].loc[df_gt.fix_year <=year]\n",
    "    a, b = stats.expon.fit(data.c_lifetime)\n",
    "    x = np.arange(0, df.lifetime.max(), 10)\n",
    "    y =  stats.expon.pdf(x, a, b)\n",
    "    ax = sns.lineplot(x=x, y=y, label=f'Exponential fit <= {year}')\n",
    "    ax.set_ylim([0, 0.0015])\n",
    "plt.savefig('../out/distributions/distribution_all_split_4_gt_gt.pdf', bbox_inches='tight')\n",
    "ax.set_ylim([0, 0.0015])\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_xlabel('Groundtruth lifetime (days)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Code age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_code_age(project='firefox')\n",
    "plt.savefig('../out/regular_code_age/year_trend_firefox_with_regular.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_code_age(project='chrome')\n",
    "plt.savefig('../out/regular_code_age/year_trend_chrome_with_regular.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_code_age(project='kernel')\n",
    "plt.savefig('../out/regular_code_age/year_trend_kernel_with_regular.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Httpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='httpd', aggregate=True)\n",
    "ax.set_xticks(range(2000, 2019, 2))\n",
    "plt.savefig('../out/regular_code_age/year_trend_httpd_with_regular.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='php', aggregate=True)\n",
    "ax.set_xticks(range(2002, 2021, 2))\n",
    "plt.savefig('../out/regular_code_age/year_trend_regular_php.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='qemu', aggregate=True, debug=True, min_year=2014, max_year=2020)\n",
    "ax.set_xlim(2013.5, 2020.5)\n",
    "plt.savefig('../out/regular_code_age/year_trend_qemu_with_regular.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='ffmpeg', aggregate=True)\n",
    "plt.savefig('../out/regular_code_age/year_trend_regular_ffmpeg.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='openssl', aggregate=True, debug=False, min_year=2006, max_year=2020, splits=[[2006, 2014], [2016, 2020]])\n",
    "df_proj = df_code_age.loc['openssl']\n",
    "df_proj['year'] = df_proj.index\n",
    "print(df_proj[2015])\n",
    "plt.plot([2015,], [df_proj[2015],], marker='s', color='orchid', markersize=7)\n",
    "plt.savefig('../out/regular_code_age/year_trend_openssl_with_regular.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wireshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SAMPLE_SIZE_2 = 20\n",
    "ax = plot_code_age(project='wireshark', aggregate=False, debug=True)\n",
    "ax.set_xlim(2013.75, 2019.25)\n",
    "plt.savefig('../out/regular_code_age/year_trend_wireshark_with_regular.pdf', bbox_inches='tight')\n",
    "MIN_SAMPLE_SIZE_2 = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_code_age(project='postgres', aggregate=True)\n",
    "plt.savefig('../out/regular_code_age/year_trend_regular_postgres.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = 'kernel'\n",
    "df_proj = df_code_age.loc[proj].to_frame('age').dropna()\n",
    "df_proj['year'] = df_proj.index\n",
    "sns.pointplot(data=df_proj, x='year', y='age')\n",
    "plot_hist_trend_complete(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='cat_name').count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
